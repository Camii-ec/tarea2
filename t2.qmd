---
title: "Tarea 2"
subtitle: "EYP3407 - Tópicos Aplicados en estadística"
author: 
    - Camila Echeverría
    - Francisca Vilca
format:
    html:
        code-fold: false
        embed-resources: true
        toc: true
        toc-title: "Contenidos"
---

## Pregunta 1 

*Asumiendo que $X$ es ortogonal, es decir, $X^TX = I$, obtenga el sesgo y varianza de los estimadores de mínimos cuadrados, ridge y LASSO. Compárelos y comente sus hallazgos.*


Por definición el sesgo es la diferencia entre el valor esperado del parámetro y el mismo, es decir:

$$ sesgo(\beta) = E(\beta) - \beta $$
Por lo que, para determinar el sesgo del parámetro es necesario encontrar la esperanza del mismo. En este caso, nos interesa especificamente los estimadores de mínimos cuadrados de la regresión Ridge y LASSO. Por lo que para determinar la forma del estimador de mínimos cuadrados de la regresión Ridge, primero veamos la forma de la función que se debe minimizar:

$$f(\beta_*) = (Y - X\beta)^T(Y-X\beta) + \lambda (\beta_*^T\beta_*),$$
de la expresión anterior es claro notar, que si $\lambda = 0$, se obtiene una expresión de la regresiñon lineal, por lo que no tendría mucho sentido, por otro lado, sin $\lambda \rightarrow \infty$, el impacto de la penalización aumenta y las estimaciones del coeficiente de regresión Ridge se acercarán a cero, por lo que al final la forma de determinar el $\lambda$, es crucial para el análisis de este modelo.

Ahora bien, el ínteres del procedimiento radica en determinar la forma del estimador de mínimos cuadrados de la *Regresión Ridge*, por lo que derivando la expresión anterior con respecto a $\beta_*$, se tiene:

\begin{align*}
f(\beta_* ) &= y^Ty - y^TX\beta_* - \beta_* ^T X^Ty + \beta_* ^T X^T X \beta_* + \lambda (\beta_*^T\beta_*) \\
f'(\beta_* ) &= -2X^Ty + 2X^TX\beta_* + 2\lambda\beta_*
\end{align*}

Igualando a 0:

$$\beta_* =  (X^TX + \lambda I_p)^{-1} X^Ty $$

Con esta expresión es posible calcular la esperanza de $\beta_*$, además es importante recordar que $X^TX = I_p$:

\begin{align*}
E(\beta_*) &= E((X^TX + \lambda I_p)^{-1} X^Ty) \\
&= E((X^TX + \lambda I_p)^{-1} X^T (X\beta_* + \epsilon) ) \\
&= E((X^TX + \lambda I_p)^{-1} X^TX\beta_* ) + E((X^TX + \lambda I_p)^{-1} X^T\epsilon)) \\
&= (I_p + \lambda I_p)^{-1} \beta_* + (I_p + \lambda I_p)^{-1}X^TE(\epsilon) \\
&= (1+\lambda)^{-1}\beta_*\\
&= \frac{\beta_*}{1 + \lambda}
\end{align*}

Con el valor de la $E(\beta_*)$ es posible calcular el sesgo:

$$ sesgo(\beta_*) =  \frac{\beta_*}{1 + \lambda} - \beta_* = \frac{-\beta_*\lambda}{1+\lambda}$$

De acá es claro notar que el sesgo va a depender del valor de lambda, además de que mientras más cercano a 0 el valor del lambda menos sesgo tendrá el parámetro.

Por otro lado, si calculamos la varianza de $\beta_*$, al ser un vector es lo mismo que calcular la $Cov(\beta_*)$:

\begin{align*}
Cov(\beta_*) &= Cov[(X^TX + \lambda I_p)^{-1}X^Ty] \\
&= Cov[(X^TX + \lambda I_p)^{-1}X^T X \hat\beta] \\
&= (X^TX + \lambda I_p)^{-1}(X^T X) Cov(\hat\beta)[  (X^TX + \lambda I_p)^{-1}(X^T X)]^T \\
&= (X^TX + \lambda I_p)^{-1}(X^T X) (\sigma^2(X^TX)^{-1})[  (X^TX + \lambda I_p)^{-1}(X^T X)]^T \\
&= \sigma^2 (X^TX + \lambda I_p)^{-1}(X^T X)(X^TX + \lambda I_p)^{-1}\\
&= \sigma^2 (I_p + \lambda I_p)^{-1}(I_p + \lambda I_p)^{-1}\\
&= \frac{\sigma^2}{(1+\lambda)^2}I_p
\end{align*}

De este resultado, es posible notar que si $\lambda \rightarrow 0$ la varianza se hará constante, objetivo principal en este tipo de problemas de maximización.

Para la *Regresión LASSO*, los procedimientos son similares, al igual que en el caso anterior, lo primero que debemos ver es la forma de la función que se debe minimizar:

$$f(\beta_*) = (Y - X\beta)^T(Y-X\beta) + \lambda||\beta_*||_1,$$

Debido a la norma 1 de la regresión Lasso, se dividirá el problema en dos situaciones, primero se verá cuando $\hat\beta_1 > 0$, lo que implica que $\hat\beta_{*i} \geq 0$, por lo que ahora si derivamos con respectos a $\hat\beta_{*i}$ y usando que la matriz $X$ es ortogonal, se tiene:

$$ f'(\beta_{*i} ) = -2\hat\beta_{i} + 2\beta_{*i} + \lambda $$
Luego igualando a 0 se tiene:

\begin{align*}
-2\hat\beta_{i} + 2\beta_{*i} + \lambda &= 0 \\
\beta_{*i} &= \hat\beta_{i} - \frac{\lambda}{2} \\
\beta_{*i} &= sgn(\hat\beta_i)(|\hat\beta_{i}| - \frac{\lambda}{2})^+ \\
\end{align*}

Ahora bien si vemos el caso análogo de $\hat\beta_1 < 0$, lo que implica que $\hat\beta_{*i} \leq 0$ se tiene:

$$ \beta_{*i} = (\hat\beta + \frac{\lambda}{2})^- = -(- \hat\beta  - \frac{\lambda}{2})^+ = sgn(\hat\beta_i)(|\hat\beta_{i}| - \frac{\lambda}{2})^+ $$
Una vez que tenemos una expresión para el estimador de mínimos cuadrados se debería poder calcular el valor de la esperanza para poder ver el sesgo y el de la varianza. Sin embargo, por la forma de la que se obtiene $\beta_{*i}$, resulta imposible encontrar una expresión para el sesgo y la varianza. A pesar de ello, si se le puede dar una interpretación, ya que la idea es conseguir el mejor equilibrio entre tener un estimador poco sesgado y una varianza constante y pequeña, por lo mismo el objetivo es encontrar el lambda que ayude a que estos dos objetivos se cumplan.

Al comparar los resultados, es claro notar que la regresión ridge facilita mucho la selección, pues es bastante más sencillo encontrar el valor que minimiza el sesgo y la varianza. Sin embargo, no podemos olvidar que la principal razón por la que la regresión LASSO se vuelve más complicada, se debe a que principalmente esta además de ser un método de regularización es también un método de selección por lo que dependerá del caso que de lo que nos interesará hacer cual es la que nos interesará usar.

## Pregunta 2

*Descargue el conjunto de datos `hitters`. Esta base corresponde a los datos de una liga de baseball entre las temporadas de 1986 y 1987. Para una descripción de los datos puede ver el enlace `https://cran.r-project.org/web/packages/ISLR/ISLR.pdf`. La variable de respuesta para este problema es **Salario**. Como la distribución del Salario es sesgada, se debe tomar la transformación Y = log(Salario).*

```{r echo = FALSE}
#| message: false
#| warning: false

library(ISLR)
library(tidyverse)
library(rio)
library(leaps)
library(glmnet)
library(caret)
library(corrplot)
library(kableExtra)
```

```{r echo=FALSE, results='hide'}
datos <- Hitters

str(datos)
summary(datos)

datos <- na.omit(datos)
datos$Salary <- log(datos$Salary)
```


a) ¿Cuáles son las características más importantes para predecir el salario de los jugadores?

Una forma bastante sencilla para saber cual de las características más importantes para predecir el salario de los jugadores es a través de la correlación de los datos. Si revisamos las variables numéricas y usando la función `corrplot()` se puede visualizar de forma sencilla que variables tienen mayor incidencia en los datos.

```{r echo=FALSE}
a <- datos %>% 
  select(-League,-Division,-NewLeague)
corrplot(cor(a),method = "ellipse")
```

De la figura anterior vemos que existen 2 grupos de variables relacionadas entre ellas, ya que estan las caracteristicas de la temporada y las caracteristicas historicas. Sin embargo, para el salario las variables con mayor relación son `CRuns`, `CHits` y `CAtBat` todas con más de $50\%$ de relación.

i) Ajuste y visualize métodos de regularización vistos en clase (LASSO, Elastic-Net) incluyendo LASSO adaptativo

Realizando un ajuste de los datos, construyendo una grilla para guardar los posibles valores de lambda y fijando el valor de $\alpha = 1$, para ajustar una regresión Lasso, se tiene:

- **Regresión Lasso**

```{r}
x <- model.matrix(Salary ~., datos)[,-1]
y <- datos$Salary

grilla <- 10^seq(10, -2, length = 100)

set.seed(3312)

mod_lasso <- glmnet(x, y, alpha = 1, lambda = grilla)

cv_lasso <- cv.glmnet(x, y, alpha = 1)
lambda <- cv_lasso$lambda.min #0.003980233

lasso_2.0 <- predict(mod_lasso, type = "coefficients", s = lambda)
```

Con lo anterior, es posible determinar los valores de los predictores de la regresión Lasso, que son:


```{r echo = FALSE}

tabla_datos1 <- as.matrix(lasso_2.0) 

tabla_datos1[-1,] %>% 
  data.frame() %>% 
  rename("pred" = contains(".")) %>% 
  ggplot(aes(x = rownames(tabla_datos1)[-1], y = pred)) +
  geom_col() +
  geom_hline(yintercept = 0) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = NULL, y = "Valor", title = "Predictores Lasso")

colnames(tabla_datos1) <- c("Predictores Lasso")

#knitr::kable(tabla_datos1, digits = 4, align = "c") %>% 
#  kable_styling( position="center")

```


- **Elastic-Net:**

Aqui explicar q este método elige al mejor de los alpha y despues, realiza el método de regularización muy similar a los otros dos anteriores, que se puede ver su paso a paso de la siguiente forma:

```{r}
library(caret)

cv_5 <-  trainControl(method = "cv", number = 5)

hit_elnet <-  train(
  Salary ~ ., data = datos,
  method = "glmnet",
  trControl = cv_5
)

hit_elnet$bestTune

mod_elnet <- glmnet(x, y, 
                    alpha = hit_elnet$bestTune[1],
                    lambda = as.numeric(hit_elnet$bestTune[2]))

cv_elnet <- cv.glmnet(x, y, alpha = hit_elnet$bestTune[1])
lambda <- cv_elnet$lambda.min #0.1215506

elnet_2.0 <- predict(mod_elnet, type = "coefficients", s = lambda)

```


Con lo anterior, es posible determinar los valores de los predictores de la regresión Elastic-Net, son:

```{r echo = FALSE}

tabla_datos3 <- as.matrix(elnet_2.0)

tabla_datos3[-1,] %>% 
  data.frame() %>% 
  rename("pred" = contains(".")) %>% 
  ggplot(aes(x = rownames(tabla_datos3)[-1], y = pred)) +
  geom_col() +
  geom_hline(yintercept = 0) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = NULL, y = "Valor", title = "Predictores Elastic-Net")

colnames(tabla_datos3) <- c("Predictores Elastic-Net")

#knitr::kable(tabla_datos3, digits = 4, align = "c") %>% 
#  kable_styling( position="center")

```


- **Lasso Adaptativo**

Al igual que en el caso de la regresión Lasso, el valor de $\alpha$ se fija en $1$. Sin embargo, la mayor diferencia, radica en que se agrega un factor de penalización conocido como $\gamma$, que se agrega como un peso al momento de crear el modelo, por lo que se tiene:

```{r}
cv_ridge <- cv.glmnet(x, y, alpha = 0)

peso <- 1/abs(matrix(coef(
  cv_ridge, s=cv_ridge$lambda.min)[, 1][2:(ncol(x)+1)] ))^1 #Gamma=1

mod_lassopro <- glmnet(x, y, alpha = 1, penalty.factor = peso)

cv_lassopro <- cv.glmnet(x, y, alpha = 1, penalty.factor = peso)

lambda <- cv_lassopro$lambda.min #0.1215506

lassopro_2.0 <- predict(mod_lassopro, type = "coefficients", s = lambda)

```


Con lo anterior, es posible determinar los valores de los predictores de la regresión Lasso Adaptativo, que son:

```{r echo = FALSE}

tabla_datos4 <- as.matrix(lassopro_2.0)

tabla_datos4[-1,] %>% 
  data.frame() %>% 
  rename("pred" = contains(".")) %>% 
  ggplot(aes(x = rownames(tabla_datos4)[-1], y = pred)) +
  geom_col() +
  geom_hline(yintercept = 0) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = NULL, y = "Valor", title = "Predictores Lasso Adaptativo")

colnames(tabla_datos4) <- c("Predictores Lasso Adaptativo")

#knitr::kable(tabla_datos4, digits = 4, align = "c") %>% 
#  kable_styling( position="center")

```


ii) ¿Cuáles son los mejores predictores seleccionados por cada método? ¿Son diferentes? Si lo son, ¿por qué?

Los mejores predictores por cada método, deberían ser aquellos mayor explicación le dan a la variable `Salario`, y es claro ver que la mayoría coincide en la categoría `Years`,`Walks`,`LeagueN` y `DivisionW`. En cada método varía levemente el predictor, pero estos son los que más influyen en general, como se muestra en la tabla a continuación:

```{r echo = FALSE}

tabla_datos5 <- cbind(tabla_datos1,tabla_datos3,tabla_datos4)

colnames(tabla_datos5) <- c("Lasso","Elastic-Net","Lasso Adaptativo")

knitr::kable(tabla_datos5, digits = 4, align = "c") %>% 
  kable_styling( position="center") %>% 
  row_spec(c(15,16,8,7), bold=T, background="purple",color = "white", align="c")

```

La variación es mínima y tiene estricta relación a la forma en la como se calculan estos mismos predictores. Sin embargo, todos tienen el mismo comportamiento.

b) ¿Cuál método es mejor para predecir el salario de los jugadores? Para hacer la decisión considere una set de entrenamiento (60%), validación (20%) y test (20%). Si los métodos considerados tienen parámetros que calibrar, entonces se debe ajustar el modelo con el set de datos de entrenamiento, se debe elegir los parámetros a calibrar minimizando el error de predicción en el set de validación y se debe reportar la predicción final con el set de datos de testeo. Se debe repetir este procedimiento 10 veces y reportar los resultados promedio (Nota: puede ver más detalles sobre el set de validación en la página 176 del libro “An Introduction to Statistical Learning” de James, Witten, Hastie y Tibshirani)


- Compare el MSE promedio obtenido en los set de datos de testeo considerando 
  (a) mínimos cuadrados
  (b) regresión Ridge
  (c) LASSO
  (d) Elastic-Net
  (e) LASSO adaptativo.

Para comparar los MSE promedio obtenido en cada set de datos, lo primero que se hara será crear la función que calcule dicho valor, tanto paralos datos de validación, como los de testeo:

```{r}
calcular_mseval <- function(prediccion){
  mse <- mean((prediccion - y[val[[i]]])^2)
  return(mse)
}

calcular_msetest <- function(prediccion){
  mse <- mean((prediccion - y[test[[i]]])^2)
  return(mse)
}
```

Luego, como dice el enunciado, lo primero que se hará es separar los datos en entrenamiento que se llamara `train`, en los de validación que serán `val` y los de testeo que serán `test`, todo esto de manera aleatoria pero fijando la semilla: 

```{r}
train <- list()
val <- list()
test <- list()

set.seed(3312)
for(i in 1:10){
  train[[i]] <- sample(1:nrow(datos), 0.6*nrow(datos))
  val[[i]] <- sample(c(1:nrow(datos))[-train[[i]]], 0.2*nrow(datos))
  test[[i]] <- c(1:nrow(datos))[-c(train[[i]], val[[i]])]
}
```

Una vez distribuidos los datos de la base se tiene, comenzamos a realizar el algoritmo, para estimar el modelo de Lasso, usando los datos de entrenamientos, ajustando los parámetro según el error en los datos de validación y finalmente se evalua el modelo con los datos de testeo, este procedimiento se repite 10 veces, para poder calcular el MSE promedio para el método Lasso, cuyo procedimiento se observa a continuación:

```{r}

# Método Lasso

mse_lasso <- c()
coef_lasso <- list()

for(i in 1:10){
  
  # Modelo con los datos de entrenamiento
  cv_lasso <- cv.glmnet(x[train[[i]],], y[train[[i]]], alpha = 1, lambda = grilla, 
                        nfolds = 10, keep = TRUE)
  lambda <- cv_lasso$lambda
  
  # Ajustamos el parámetro según el error en los datos de validación
  evaluacion <- predict(cv_lasso, newx = x[val[[i]],], s = lambda)
  mse <- apply(evaluacion, 2, calcular_mseval)
  
  # Evaluamos el modelo en los datos de testeo
  
  testeo <- predict(cv_lasso, newx = x[test[[i]],], s = lambda[which.min(mse)])
  mse_lasso[i] <- apply(testeo, 2, calcular_msetest)
  
  coef_lasso[[i]] <- predict(cv_lasso, s = lambda[which.min(mse)], type = "coefficients") %>% 
    as.matrix() %>%
    data.frame()
}
```

Una vez probado el método de Lasso, es posible probar los otros métodos, tal como se presentan en la pregunta anterior, estos serían, el método de Ridge, Lasso Adaptativo y Elastic-Net. Además, probamos la estimación de los mínimos cuadrados ordinarios:  

```{r}
# Metodo de Ridge y Lasso Adaptativo

mse_ridge <- c()
mse_lassoA <- c()

coef_ridge <- list()
coef_lassoA <- list()

for(i in 1:10){
  
  ## Para regresión Ridge
  # Modelo con los datos de entrenamiento
  cv_ridge <- cv.glmnet(x[train[[i]],], y[train[[i]]], alpha = 0, lambda = grilla, 
                        nfolds = 10, keep = TRUE)
  lambda <- cv_ridge$lambda
  
  # Ajustamos el parámetro según el error en los datos de validación
  evaluacion <- predict(cv_ridge, newx = x[val[[i]],], s = lambda)
  mse <- apply(evaluacion, 2, calcular_mseval)
  
  # Evaluamos el modelo en los datos de testeo
  
  testeo <- predict(cv_ridge, newx = x[test[[i]],], s = lambda[which.min(mse)])
  mse_ridge[i] <- apply(testeo, 2, calcular_msetest)
  
  # Guardamos los coeficientes para el mejor lambda 
  coef_ridge[[i]] <- predict(cv_ridge, s = lambda[which.min(mse)], type = "coefficients") %>% 
    as.matrix() %>%
    data.frame()
  
  ## Para Lasso Adaptativo
  peso <- 1/abs(matrix(coef(
    cv_ridge, s=lambda[which.min(mse)])[,1][2:(ncol(x)+1)]))
  
  cv_lassoA <- cv.glmnet(x[train[[i]],], y[train[[i]]], alpha = 1, 
                         penalty.factor = peso, nfolds = 10, keep = TRUE)
  
  lambda <- cv_lassoA$lambda
  
  evaluacion <- predict(cv_lassoA, newx = x[val[[i]],], s = lambda)
  mse <- apply(evaluacion, 2, calcular_mseval)
  
  # Evaluamos el modelo en los datos de testeo
  
  testeo <- predict(cv_lassoA, newx = x[test[[i]],], s = lambda[which.min(mse)])
  mse_lassoA[i] <- apply(testeo, 2, calcular_msetest)
  
  coef_lassoA[[i]] <- predict(cv_lassoA, s = lambda[which.min(mse)], type = "coefficients") %>% 
    as.matrix() %>%
    data.frame()
}

# Método de Elastic-Net

mse_elastic <- c()
cv <-  trainControl(method = "cv", number = 10)
coef_elastic <- list()

for(i in 1:10){
  
  alpha <-  train(Salary ~ ., data = datos[train[[i]],],
    method = "glmnet",
    trControl = cv,
    tuneLength = 10)$bestTune[1]
  
  # Modelo con los datos de entrenamiento
  cv_elastic <- cv.glmnet(x[train[[i]],], y[train[[i]]], alpha = alpha, 
                          lambda = grilla, nfolds = 10, keep = TRUE)
  lambda <- cv_elastic$lambda
  
  # Ajustamos el parámetro según el error en los datos de validación
  evaluacion <- predict(cv_elastic, newx = x[val[[i]],], s = lambda)
  mse <- apply(evaluacion, 2, calcular_mseval)
  
  # Evaluamos el modelo en los datos de testeo
  
  testeo <- predict(cv_elastic, newx = x[test[[i]],], s = lambda[which.min(mse)])
  mse_elastic[i] <- apply(testeo, 2, calcular_msetest)
  
  coef_elastic[[i]] <- predict(cv_elastic, s = lambda[which.min(mse)], type = "coefficients") %>% 
    as.matrix() %>% 
    data.frame()
}

# Método de mínimos cuadrado ordinarios:

mse_mco <- c()
coef_mco <- list()

for(i in 1:10){
  mod_lm <- lm(Salary ~., data = datos[train[[i]],])
  testeo <- predict(mod_lm, datos[test[[i]],])
  mse_mco[i] <- mean((testeo - y[test[[i]]])^2)
  coef_mco[[i]] <- coef(mod_lm) %>% 
    data.frame()
}

```



```{r echo=FALSE}

# MSE promedio para el método Lasso:
prom_mse_lasso <- mean(mse_lasso)

# MSE promedio para el método Ridge:
prom_mse_ridge <- mean(mse_ridge)

# MSE promedio para el método Lasso Adaptativo:
prom_mse_lassoA <-mean(mse_lassoA)

# MSE promedio para el método Elastic-Net:
prom_mse_elastic <- mean(mse_elastic)

# MSE promedio para el método de mínimos cuadrado:
prom_mse_mco <- mean(mse_mco)

tabla_datos6 <- cbind(prom_mse_lasso,prom_mse_ridge,prom_mse_lassoA,prom_mse_elastic,prom_mse_mco)


colnames(tabla_datos6) <- c("Lasso","Ridge","Lasso Adaptivo", "Elastic-Net","MCO")

row.names(tabla_datos6) <- c("MSE")

knitr::kable(tabla_datos6, digits = 4, align = "c") %>% 
  kable_styling( position="center")

```



- Visualize los resultados obtenidos para comparar los modelos. Muestre los resultados solamente para el mejor parámetro de calibración elegido

No se que visualizar aaaaaaaa

```{r}
#| message: false

coef_lasso <- purrr::list_cbind(coef_lasso)
coef_ridge <- purrr::list_cbind(coef_ridge)
coef_lassoA <- purrr::list_cbind(coef_lassoA)
coef_elastic <- purrr::list_cbind(coef_elastic)
coef_mco <- purrr::list_cbind(coef_mco)

coef <- data.frame("Lasso" = rowMeans(coef_lasso), 
                   "Ridge" = rowMeans(coef_ridge), 
                   "LassoA" = rowMeans(coef_lassoA), 
                   "ElasticNet" = rowMeans(coef_elastic), 
                   "MCO" = rowMeans(coef_mco),
                   "Coef" = rownames(coef_lasso)) 

coef %>% 
  pivot_longer(Lasso:MCO) %>% 
  filter(Coef != "(Intercept)") %>% 
  ggplot(aes(x = Coef, y = value, fill = name)) +
  geom_col() +
  geom_hline(yintercept = 0, col = "black") +
  facet_wrap(~name, scales = "free_y", ncol = 2) +
  scale_fill_brewer(palette = "Dark2") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = NULL, y = NULL)
  
```


- ¿Qué métodos generan el mejor error de predicción? ¿Por qué estos métodos funcionan bien? ¿Los métodos eligen el mismo subconjunto de variables? Explique y amplíe sus respuestas.

El método que genera el mejor error de predicción, sería aquel que tenga menor MSE, pues es el que menos se equivoca al momento de predecir. El método de Ridge sería el ideal en este caso, ya que su error es cercano al 0.42. Es claro, de la tabla anterior que en general el MSE, no se aleja mucho pero es mejor el método Ridge.

La tabla 5, muestra de manera resumida los valores de los predictores y de aquí es bastante claro ver que los métodos eligen casi el mismo subconjunto de variables




